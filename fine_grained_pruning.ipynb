{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9194e2e2-f5e6-49dd-8d26-c44e9f1b56bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:12.158606Z",
     "iopub.status.busy": "2024-12-07T00:58:12.158357Z",
     "iopub.status.idle": "2024-12-07T00:58:15.175446Z",
     "shell.execute_reply": "2024-12-07T00:58:15.174723Z",
     "shell.execute_reply.started": "2024-12-07T00:58:12.158586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.1.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.16.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: thop in /usr/local/lib/python3.11/dist-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.1.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->thop) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Install PyTorch with MPS support\n",
    "!pip install torch torchvision\n",
    "# Install thops for metric analysis\n",
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1867da-f336-4546-b633-0cabb87fdc4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:15.176858Z",
     "iopub.status.busy": "2024-12-07T00:58:15.176652Z",
     "iopub.status.idle": "2024-12-07T00:58:17.221221Z",
     "shell.execute_reply": "2024-12-07T00:58:17.220534Z",
     "shell.execute_reply.started": "2024-12-07T00:58:15.176858Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import utils.dependencies as utils\n",
    "import utils.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca9aca8-d04b-4ac4-a649-4f8f62285aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:17.222776Z",
     "iopub.status.busy": "2024-12-07T00:58:17.222174Z",
     "iopub.status.idle": "2024-12-07T00:58:17.226238Z",
     "shell.execute_reply": "2024-12-07T00:58:17.225697Z",
     "shell.execute_reply.started": "2024-12-07T00:58:17.222755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base model configuration\n",
    "BASE_MODEL_NAME = 'efficientnet_b0'  # Change this to switch models (e.g., 'resnet18', 'vgg16')\n",
    "NUM_CLASSES = 10  # Adjust based on your dataset (e.g., 10 for CIFAR10)\n",
    "\n",
    "# Pruning configuration\n",
    "PRUNING_METHOD = 'l1_unstructured'  # Options: 'l1_unstructured', 'random_unstructured', etc.\n",
    "PRUNING_RATIO = 0.8  # Percentage of weights to prune (e.g., 0.2 for 20%)\n",
    "\n",
    "# Paths\n",
    "STATE_DICT_PATH = './models/finetuned_base_model.pth'  # Path to the saved state dictionary\n",
    "SAVE_DIR = './pruned_models/'  # Directory to save pruned models and metrics\n",
    "\n",
    "# Ensure SAVE_DIR exists\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815b639c-b4be-43d3-9c45-9640fee79b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:17.227876Z",
     "iopub.status.busy": "2024-12-07T00:58:17.227698Z",
     "iopub.status.idle": "2024-12-07T00:58:17.234385Z",
     "shell.execute_reply": "2024-12-07T00:58:17.233852Z",
     "shell.execute_reply.started": "2024-12-07T00:58:17.227861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4576e4-b880-4530-b1f6-409f4a58b80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:17.236437Z",
     "iopub.status.busy": "2024-12-07T00:58:17.235081Z",
     "iopub.status.idle": "2024-12-07T00:58:19.908137Z",
     "shell.execute_reply": "2024-12-07T00:58:19.907560Z",
     "shell.execute_reply.started": "2024-12-07T00:58:17.236418Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.efficientnet_b0()\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, 10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eeadd3d-ec83-4b02-8fff-8ced5cfe1af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:19.909599Z",
     "iopub.status.busy": "2024-12-07T00:58:19.909041Z",
     "iopub.status.idle": "2024-12-07T00:58:19.971691Z",
     "shell.execute_reply": "2024-12-07T00:58:19.971087Z",
     "shell.execute_reply.started": "2024-12-07T00:58:19.909572Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the state dictionary\n",
    "state_dict = torch.load(STATE_DICT_PATH, map_location=device)\n",
    "# Load state dict into the model\n",
    "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7fdd59-0ed2-45ab-b39d-db350db889d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:19.973441Z",
     "iopub.status.busy": "2024-12-07T00:58:19.972584Z",
     "iopub.status.idle": "2024-12-07T00:58:20.010152Z",
     "shell.execute_reply": "2024-12-07T00:58:20.009641Z",
     "shell.execute_reply.started": "2024-12-07T00:58:19.973411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Sparsity: 0.00%\n",
      "Applied l1_unstructured pruning with amount=80.0%.\n"
     ]
    }
   ],
   "source": [
    "# Function to apply pruning to all Conv2d and Linear layers\n",
    "def apply_fine_grained_pruning(model, method='l1_unstructured', amount=0.2):\n",
    "    parameters_to_prune = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "    \n",
    "    # Apply pruning\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured if method == 'l1_unstructured' else prune.RandomUnstructured,\n",
    "        amount=amount,\n",
    "    )\n",
    "    print(f\"Applied {method} pruning with amount={amount*100}%.\")\n",
    "    return model\n",
    "\n",
    "def calculate_sparsity(model):\n",
    "    total_weights = 0\n",
    "    zero_weights = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            weight = module.weight.data.cpu().numpy()\n",
    "            total_weights += weight.size\n",
    "            zero_weights += (weight == 0).sum()\n",
    "    sparsity = 100. * zero_weights / total_weights\n",
    "    return sparsity\n",
    "\n",
    "# Calculate and print sparsity before pruning\n",
    "initial_sparsity = calculate_sparsity(model)\n",
    "print(f\"Initial Sparsity: {initial_sparsity:.2f}%\")\n",
    "\n",
    "# Apply pruning\n",
    "model = apply_fine_grained_pruning(model, method=PRUNING_METHOD, amount=PRUNING_RATIO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395ba4e6-fa14-486c-95f8-309628035815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:20.011477Z",
     "iopub.status.busy": "2024-12-07T00:58:20.010921Z",
     "iopub.status.idle": "2024-12-07T00:58:20.027095Z",
     "shell.execute_reply": "2024-12-07T00:58:20.026697Z",
     "shell.execute_reply.started": "2024-12-07T00:58:20.011455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed pruning reparameterization from features.0.0.\n",
      "Removed pruning reparameterization from features.1.0.block.0.0.\n",
      "Removed pruning reparameterization from features.1.0.block.1.fc1.\n",
      "Removed pruning reparameterization from features.1.0.block.1.fc2.\n",
      "Removed pruning reparameterization from features.1.0.block.2.0.\n",
      "Removed pruning reparameterization from features.2.0.block.0.0.\n",
      "Removed pruning reparameterization from features.2.0.block.1.0.\n",
      "Removed pruning reparameterization from features.2.0.block.2.fc1.\n",
      "Removed pruning reparameterization from features.2.0.block.2.fc2.\n",
      "Removed pruning reparameterization from features.2.0.block.3.0.\n",
      "Removed pruning reparameterization from features.2.1.block.0.0.\n",
      "Removed pruning reparameterization from features.2.1.block.1.0.\n",
      "Removed pruning reparameterization from features.2.1.block.2.fc1.\n",
      "Removed pruning reparameterization from features.2.1.block.2.fc2.\n",
      "Removed pruning reparameterization from features.2.1.block.3.0.\n",
      "Removed pruning reparameterization from features.3.0.block.0.0.\n",
      "Removed pruning reparameterization from features.3.0.block.1.0.\n",
      "Removed pruning reparameterization from features.3.0.block.2.fc1.\n",
      "Removed pruning reparameterization from features.3.0.block.2.fc2.\n",
      "Removed pruning reparameterization from features.3.0.block.3.0.\n",
      "Removed pruning reparameterization from features.3.1.block.0.0.\n",
      "Removed pruning reparameterization from features.3.1.block.1.0.\n",
      "Removed pruning reparameterization from features.3.1.block.2.fc1.\n",
      "Removed pruning reparameterization from features.3.1.block.2.fc2.\n",
      "Removed pruning reparameterization from features.3.1.block.3.0.\n",
      "Removed pruning reparameterization from features.4.0.block.0.0.\n",
      "Removed pruning reparameterization from features.4.0.block.1.0.\n",
      "Removed pruning reparameterization from features.4.0.block.2.fc1.\n",
      "Removed pruning reparameterization from features.4.0.block.2.fc2.\n",
      "Removed pruning reparameterization from features.4.0.block.3.0.\n",
      "Removed pruning reparameterization from features.4.1.block.0.0.\n",
      "Removed pruning reparameterization from features.4.1.block.1.0.\n",
      "Removed pruning reparameterization from features.4.1.block.2.fc1.\n",
      "Removed pruning reparameterization from features.4.1.block.2.fc2.\n",
      "Removed pruning reparameterization from features.4.1.block.3.0.\n",
      "Removed pruning reparameterization from features.4.2.block.0.0.\n",
      "Removed pruning reparameterization from features.4.2.block.1.0.\n",
      "Removed pruning reparameterization from features.4.2.block.2.fc1.\n",
      "Removed pruning reparameterization from features.4.2.block.2.fc2.\n",
      "Removed pruning reparameterization from features.4.2.block.3.0.\n",
      "Removed pruning reparameterization from features.5.0.block.0.0.\n",
      "Removed pruning reparameterization from features.5.0.block.1.0.\n",
      "Removed pruning reparameterization from features.5.0.block.2.fc1.\n",
      "Removed pruning reparameterization from features.5.0.block.2.fc2.\n",
      "Removed pruning reparameterization from features.5.0.block.3.0.\n",
      "Removed pruning reparameterization from features.5.1.block.0.0.\n",
      "Removed pruning reparameterization from features.5.1.block.1.0.\n",
      "Removed pruning reparameterization from features.5.1.block.2.fc1.\n",
      "Removed pruning reparameterization from features.5.1.block.2.fc2.\n",
      "Removed pruning reparameterization from features.5.1.block.3.0.\n",
      "Removed pruning reparameterization from features.5.2.block.0.0.\n",
      "Removed pruning reparameterization from features.5.2.block.1.0.\n",
      "Removed pruning reparameterization from features.5.2.block.2.fc1.\n",
      "Removed pruning reparameterization from features.5.2.block.2.fc2.\n",
      "Removed pruning reparameterization from features.5.2.block.3.0.\n",
      "Removed pruning reparameterization from features.6.0.block.0.0.\n",
      "Removed pruning reparameterization from features.6.0.block.1.0.\n",
      "Removed pruning reparameterization from features.6.0.block.2.fc1.\n",
      "Removed pruning reparameterization from features.6.0.block.2.fc2.\n",
      "Removed pruning reparameterization from features.6.0.block.3.0.\n",
      "Removed pruning reparameterization from features.6.1.block.0.0.\n",
      "Removed pruning reparameterization from features.6.1.block.1.0.\n",
      "Removed pruning reparameterization from features.6.1.block.2.fc1.\n",
      "Removed pruning reparameterization from features.6.1.block.2.fc2.\n",
      "Removed pruning reparameterization from features.6.1.block.3.0.\n",
      "Removed pruning reparameterization from features.6.2.block.0.0.\n",
      "Removed pruning reparameterization from features.6.2.block.1.0.\n",
      "Removed pruning reparameterization from features.6.2.block.2.fc1.\n",
      "Removed pruning reparameterization from features.6.2.block.2.fc2.\n",
      "Removed pruning reparameterization from features.6.2.block.3.0.\n",
      "Removed pruning reparameterization from features.6.3.block.0.0.\n",
      "Removed pruning reparameterization from features.6.3.block.1.0.\n",
      "Removed pruning reparameterization from features.6.3.block.2.fc1.\n",
      "Removed pruning reparameterization from features.6.3.block.2.fc2.\n",
      "Removed pruning reparameterization from features.6.3.block.3.0.\n",
      "Removed pruning reparameterization from features.7.0.block.0.0.\n",
      "Removed pruning reparameterization from features.7.0.block.1.0.\n",
      "Removed pruning reparameterization from features.7.0.block.2.fc1.\n",
      "Removed pruning reparameterization from features.7.0.block.2.fc2.\n",
      "Removed pruning reparameterization from features.7.0.block.3.0.\n",
      "Removed pruning reparameterization from features.8.0.\n",
      "Removed pruning reparameterization from classifier.1.\n",
      "Sparsity after pruning: 80.00%\n"
     ]
    }
   ],
   "source": [
    "def remove_pruning(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            try:\n",
    "                prune.remove(module, 'weight')\n",
    "                print(f\"Removed pruning reparameterization from {name}.\")\n",
    "            except ValueError:\n",
    "                print(f\"No pruning to remove for {name}.\")\n",
    "    return model\n",
    "\n",
    "# Make pruning permanent\n",
    "model = remove_pruning(model)\n",
    "# Calculate and print sparsity after pruning\n",
    "post_pruning_sparsity = calculate_sparsity(model)\n",
    "print(f\"Sparsity after pruning: {post_pruning_sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e836dbe-ea0a-4104-9262-87b8dd6763ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:20.027956Z",
     "iopub.status.busy": "2024-12-07T00:58:20.027687Z",
     "iopub.status.idle": "2024-12-07T00:58:20.070425Z",
     "shell.execute_reply": "2024-12-07T00:58:20.070063Z",
     "shell.execute_reply.started": "2024-12-07T00:58:20.027916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model saved at ./pruned_models/finegrained_prune_0.8.pth.\n"
     ]
    }
   ],
   "source": [
    "PRUNED_STATE_DICT_PATH = os.path.join(SAVE_DIR, 'finegrained_prune_0.8.pth')\n",
    "torch.save(model.state_dict(), PRUNED_STATE_DICT_PATH)\n",
    "print(f\"Pruned model saved at {PRUNED_STATE_DICT_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8b781c-b985-43d0-a363-ab4ef228d41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:20.071956Z",
     "iopub.status.busy": "2024-12-07T00:58:20.071590Z",
     "iopub.status.idle": "2024-12-07T00:58:20.077285Z",
     "shell.execute_reply": "2024-12-07T00:58:20.076884Z",
     "shell.execute_reply.started": "2024-12-07T00:58:20.071939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze all layers except the classifier\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Define the layers to unfreeze (last two blocks)\n",
    "layers_to_unfreeze = ['features.5', 'features.6', 'features.7']\n",
    "\n",
    "# Unfreeze the specified layers\n",
    "utils.unfreeze_layers(model, layers_to_unfreeze)\n",
    "\n",
    "# Define optimizer to include only trainable parameters\n",
    "optimizer = optim.SGD(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=0.01,  \n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "# Define a learning rate scheduler for fine-tuning\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb01acb-e1f3-45c5-941d-1311dc94e082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T00:58:20.078322Z",
     "iopub.status.busy": "2024-12-07T00:58:20.077846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "--- Epoch 1 ---\n",
      "Train Loss: 0.4252 | Train Acc: 85.88% | Time: 63.94s\n",
      "Val Loss: 0.2360 | Val Acc: 92.02%\n",
      "Best model saved with Val Acc: 92.02%\n",
      "\n",
      "--- Epoch 2 ---\n",
      "Train Loss: 0.2095 | Train Acc: 92.77% | Time: 61.73s\n",
      "Val Loss: 0.2075 | Val Acc: 93.02%\n",
      "Best model saved with Val Acc: 93.02%\n",
      "\n",
      "--- Epoch 3 ---\n",
      "Train Loss: 0.1447 | Train Acc: 95.07% | Time: 59.48s\n",
      "Val Loss: 0.2091 | Val Acc: 92.96%\n",
      "No improvement this epoch.\n",
      "\n",
      "--- Epoch 4 ---\n",
      "Train Loss: 0.1083 | Train Acc: 96.16% | Time: 60.43s\n",
      "Val Loss: 0.1810 | Val Acc: 94.04%\n",
      "Best model saved with Val Acc: 94.04%\n",
      "\n",
      "--- Epoch 5 ---\n",
      "Train Loss: 0.0846 | Train Acc: 97.06% | Time: 58.65s\n",
      "Val Loss: 0.1867 | Val Acc: 94.06%\n",
      "Best model saved with Val Acc: 94.06%\n",
      "\n",
      "--- Epoch 6 ---\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "save_path = f'./models/finegrained_prune_ratio_{PRUNING_RATIO}'\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Get the data loaders\n",
    "train_loader, val_loader, test_loader = utils.get_data_loaders()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"--- Epoch {epoch} ---\")    \n",
    "    # Train\n",
    "    train_loss, train_acc = utils.train_epoch(model, device, train_loader, optimizer)  \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    # Validate\n",
    "    val_loss, val_acc = utils.validate_epoch(model, device, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    # Step the scheduler\n",
    "    scheduler.step()    \n",
    "    # Save the best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Best model saved with Val Acc: {best_val_acc:.2f}%\\n\")\n",
    "    else:\n",
    "        print(\"No improvement this epoch.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd935b93-e4b8-42c1-b7a7-d405f41cb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save metrics plots and table\n",
    "metrics.generate_and_save_metrics(\n",
    "    model=model, \n",
    "    device=device, \n",
    "    test_loader=test_loader, \n",
    "    criterion=utils.criterion, \n",
    "    model_name=f'fine_grained_prune_{PRUNING_RATIO}', \n",
    "    pruning_ratio=PRUNING_RATIO, \n",
    "    description= f'Model with fine grained pruning',\n",
    "    train_losses=train_losses,\n",
    "    train_accuracies=train_accuracies,\n",
    "    val_losses=val_losses,\n",
    "    val_accuracies=val_accuracies,\n",
    "    save_dir='metrics_plots'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
